#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\input{common_preamble}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman palatino
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_title "Reproducible software vs. reproducible research"
\pdf_author "Fernando Perez"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref page
\pdf_pdfusetitle true
\pdf_quoted_options "urlcolor=blue"
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.6cm
\topmargin 2.6cm
\rightmargin 2.6cm
\bottommargin 2.6cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Reproducible software vs.
 reproducible research 
\end_layout

\begin_layout Author
Fernando Pérez
\begin_inset Newline newline
\end_inset

Helen Wills Neuroscience Institute, 
\begin_inset Newline newline
\end_inset

University of California at Berkeley.
\begin_inset Newline newline
\end_inset


\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

http://fperez.org
\end_layout

\end_inset


\family typewriter

\begin_inset Newline newline
\end_inset

Fernando.Perez@Berkeley.edu
\end_layout

\begin_layout Quotation

\size footnotesize
\emph on
Note:
\emph default
 this text should be considered a working draft and is 
\emph on
not
\emph default
 a complete academic article (e.g.
 it currently lacks a proper set of bibliographic references).
 It is offered here as a complement to a talk delivered at the 2011 annual
 meeting of the AAAS.
\end_layout

\begin_layout Standard
As an active member of both the scientific research and the open-source
 software development communities, I have observed that the latter often
 lives up better than the former to our ideals of scientific openness and
 reproducibility.
 I will explore the reasons behind this, and I will argue that these problems
 are particularly acute in computational domains where they should be in
 fact less prevalent.
 I will discuss how we can draw specific lessons from the open source community
 both in terms of technical approaches and of changing the structure of
 incentives, to make progress towards a more solid base for reproducible
 computational research.
\end_layout

\begin_layout Section
Outline of book chapter
\end_layout

\begin_layout Itemize
Levels of reproducibility: replication, validation, reproduction, new constructi
on.
\end_layout

\begin_layout Itemize
Conditions: clarity, transparency and traceability, predictability (which
 requires automation), communicability
\end_layout

\begin_layout Subsection
Problem: credibility crisis in computationally-driven science
\end_layout

\begin_layout BeginFrame
Computing: part of the DNA of science
\end_layout

\begin_layout FrameSubtitle
Much more than 
\begin_inset Quotes eld
\end_inset

the third branch
\begin_inset Quotes erd
\end_inset

 of science
\end_layout

\begin_layout Itemize
An avalanche of 
\color blue
experimental quantitative data
\end_layout

\begin_deeper
\begin_layout Itemize
Biology, genetics, neuroscience, astronomy, climate modeling...
\end_layout

\end_deeper
\begin_layout Itemize
All scientists must now do real computing
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Big Data
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Cloud computing
\begin_inset Quotes erd
\end_inset

, etc: lots of buzzwords...
\end_layout

\begin_deeper
\begin_layout Itemize
They will 
\series bold
NOT
\series default
 automatically produce good science
\end_layout

\end_deeper
\begin_layout Itemize
Good computing is now a 
\color blue
necessary
\color inherit
 (though 
\color red
not sufficient
\color inherit
!) condition for good science.
\end_layout

\begin_layout BeginFrame
A crisis of credibility and real issues
\end_layout

\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

<+>
\end_layout

\end_inset


\series bold
The Duke clinical trials 
\color red
scandal
\color inherit
 
\series default
- Potti/Nevin
\end_layout

\begin_deeper
\begin_layout Itemize
A compounding of (common and otherwise) data analysis errors.
\end_layout

\begin_layout Itemize
No materials allowing validation/reproduction of results.
\end_layout

\begin_layout Itemize

\series bold
\color red
Patients were harmed
\series default
\color inherit
.
\end_layout

\begin_layout Itemize
Lawsuits, resignations.
\end_layout

\begin_layout Itemize
Major policy reviews and changes: NCI, IOM, ...
\end_layout

\begin_layout Itemize
More: see 
\color blue

\begin_inset CommandInset href
LatexCommand href
name "K. Baggerly's \"starter set\" page"
target "http://bioinformatics.mdanderson.org/Supplements/ReproRsch-All/Modified/StarterSet/index.html"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

<+>
\end_layout

\end_inset

The Duke situation is more 
\color red
common
\color inherit
 than we'd like to believe!
\end_layout

\begin_deeper
\begin_layout Itemize
Begley & Ellis, Nature, 3/28/12: 
\emph on
\color blue
Drug development: Raise standards for preclinical cancer research.
\end_layout

\begin_layout Itemize

\color red
47 out of 53 
\begin_inset Quotes eld
\end_inset

landmark papers
\begin_inset Quotes erd
\end_inset

 could not be replicated.
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

<+>
\end_layout

\end_inset

Nature, Feb 2012, Ince et al: 
\emph on
\color blue
The case for open computer programs
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

The scientific community places 
\color red
more faith in computation than is justified
\color inherit

\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

anything less than the release of actual source code is 
\color red
an indefensible approach
\color inherit
 for any scientific results that depend on computation
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Retraction rates are going up (find citation)
\end_layout

\begin_layout Pause

\end_layout

\begin_layout Standard
\align center

\size large
The 
\color blue
rigor
\color inherit
, 
\color blue
openness
\color inherit
, culture of 
\color blue
validation
\color inherit
, 
\color blue
collaboration
\color inherit
 and other aspects of science 
\series bold
\color blue
must
\series default
\color inherit
 also become part of scientific computing.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sec:lifecycle"

\end_inset

The lifecycle of computational research
\end_layout

\begin_layout Standard
Scientific research has become pervasively computational.
 In addition to experiment and theory, the notions of simulation and data-intens
ive discovery have emerged as third and fourth pillars of science 
\begin_inset CommandInset citation
LatexCommand cite
key "4th-paradigm"

\end_inset

.
 Today, even theory and experiment are computational, as virtually all experimen
tal work requires computing (whether in data collection, pre-processing
 or analysis) and most theoretical work requires symbolic and numerical
 support to develop and refine models.
 Scanning the pages of any major scientific journal, one is hard-pressed
 to find a publication in any discipline that doesn't depend on computing
 for its findings.
\end_layout

\begin_layout Standard
And yet, for all its importance, computing is often treated as an afterthought
 both in the training of our scientists and in the conduct of everyday research.
 Most working scientists have witnessed how computing is treated as a task
 of secondary importance that students and postdocs learn 
\begin_inset Quotes eld
\end_inset

on the go
\begin_inset Quotes erd
\end_inset

 with little training to ensure that results are trustworthy, comprehensible
 and ultimately a solid foundation for reproducible outcomes.
 Software and data are stored with poor organization, documentation and
 tests.
 A patchwork of software tools is used with limited attention paid to capturing
 the complex workflows that emerge, and the evolution of code is often not
 tracked over time, making it difficult to understand how a result was obtained.
 Finally, many of the software packages used by scientists in research are
 proprietary and closed-source, preventing the community from having a complete
 understanding of the final scientific results.
 The consequences of this cavalier approach are serious.
 Consider, just to name two widely publicized cases, the loss of public
 confidence in the
\begin_inset Quotes eld
\end_inset

Climategate
\begin_inset Quotes erd
\end_inset

 fiasco 
\begin_inset CommandInset citation
LatexCommand cite
key "Hef10"

\end_inset

 or the Duke cancer trials scandal, where sloppy computational practices
 likely led to severe health consequences for several patients 
\begin_inset CommandInset citation
LatexCommand cite
key "Cou10"

\end_inset

.
 
\end_layout

\begin_layout Standard
This is a large and complex problem that requires changing the educational
 process for new scientists, the incentive models for promotions and rewards,
 the publication system, and more.
 We do not aim to tackle all of these issues here, but our belief is that
 a central element of this problem is the nature and quality of the software
 tools available for computational work in science.
 Based on our experience over the last decade as practicing researchers,
 educators and software developers, we propose an integrated approach to
 computing where the entire life-cycle of scientific research is considered,
 from the initial exploration of ideas and data to the presentation of final
 results.
 Briefly, this life-cycle can be broken down into the following phases:
\end_layout

\begin_layout Itemize

\series bold
Individual exploration:
\series default
 a single investigator tests an idea, algorithm or question, likely with
 a small-scale test data set or simulation.
\end_layout

\begin_layout Itemize

\series bold
Collaboration:
\series default
 if the initial exploration appears promising, more often than not some
 kind of collaborative effort ensues.
\end_layout

\begin_layout Itemize

\series bold
Production-scale execution:
\series default
 large data sets and complex simulations often require the use of clusters,
 supercomputers or cloud resources in parallel.
\end_layout

\begin_layout Itemize

\series bold
Publication:
\series default
 whether as a paper or an internal report for discussion with colleagues,
 results need to be presented to others in a coherent form.
\end_layout

\begin_layout Itemize

\series bold
Education:
\series default
 ultimately, research results become part of the corpus of a discipline
 that is shared with students and colleagues, thus seeding the next cycle
 of research.
\end_layout

\begin_layout Standard
In this project, we tackle the following problem.

\series bold
 There are no software tools capable of spanning the entire lifecycle of
 computational research.

\series default
 The result is that researchers are forced to use a large number of disjoint
 software tools in each of these phases in an awkward workflow that hinders
 collaboration and reduces efficiency, quality, robustness and reproducibility.
\end_layout

\begin_layout Standard
These can be illustrated with an example: a researcher might use Matlab
 for prototyping, develop high-performance code in C, run post-processing
 by twiddling controls in a Graphical User Interface (GUI), import data
 back into Matlab for generating plots, polish the resulting plots by hand
 in Adobe Illustrator, and finally paste the plots into a publication manuscript
 or PowerPoint presentation.
 But what if months later the researcher realizes there is a problem with
 the results? What are the chances they will be able to know what buttons
 they clicked, to reproduce the workflow that can generate the updated plots,
 manuscript and presentation? What are the chances that other researchers
 or students could reproduce these steps to learn the new method or understand
 how the result was obtained? How can reviewers validate that the programs
 and overall workflow are free of errors? Even if the researcher successfully
 documents each program and the entire workflow, they have to carry an immense
 cognitive burden just to keep track of everything.
\end_layout

\begin_layout Subsubsection
The patchwork of existing software tools
\end_layout

\begin_layout Standard
For 
\series bold
individual exploratory work
\series default
, researchers use various interactive computing environments: Microsoft
 Excel, Matlab, Mathematica, Sage 
\begin_inset CommandInset citation
LatexCommand cite
key "sage"

\end_inset

, and more specialized systems like R, SPSS and STATA for statistics.
 These environments combine interactive, high-level programming languages
 with a rich set of numerical and visualization libraries.
 The impact of these environments cannot be overstated; they are used almost
 universally by researchers for rapid prototyping, interactive exploration
 and data analysis and visualization.
 However, these environments have a number of limitations: (a) some of them
 are proprietary and/or expensive (Excel, Matlab, Mathematica), (b) most
 (except for Sage) are focused on coding in a single, relatively slow, programmi
ng language and (c) most (except for Sage and Mathematica) do not have a
 document format that is rich, i.e., that can include text, equations, images
 and video in addition to source code.
 While the use of proprietary tools isn't a problem 
\emph on
per se
\emph default
 and may be a good solution in industry, it is a barrier to scientific collabora
tion and to the construction of a common scientific heritage.
 Scientists can't share work unless all colleagues can purchase the same
 package, students are forced to work with black boxes they are legally
 prevented from inspecting (spectacularly defeating the very essence of
 scientific inquiry), and years down the road we may not be able to reproduce
 a result that relied on a proprietary package.
 Furthermore, because of their limitations in performance and handling large,
 complex code bases, these tools are mostly used for prototyping: researchers
 eventually have to switch tools for building production systems.
\end_layout

\begin_layout Standard
For 
\series bold
collaboration
\series default
, researchers currently use a mix of email, version control systems and
 shared network folders (Dropbox, etc.).
 Version control systems (Git, SVN, CVS, etc.) are critically important in
 making research collaborative and reproducible.
 They allow groups to work collaboratively on documents and track how those
 documents evolve over time.
 Ideally, all aspects of computational research would be hosted on publicly
 available version control repositories, such GitHub or Google Code.
 Unfortunately, the most common approach is still for researchers to email
 documents to each other.
 This form of collaboration makes it nearly impossible to track the development
 of a large project and establish reproducible and testable workflows.
 When it works at all, it most certainly doesn't scale beyond a very small
 group, as painfully experienced by anyone who has participated in the madness
 of a flurry of email attachments.
 
\end_layout

\begin_layout Standard
For 
\series bold
production-scale execution
\series default
, researchers are forced to turn away from the convenient interactive computing
 environments to compiled code (C/C++/Fortran) and parallel computing libraries
 (MPI, Hadoop), as most interactive systems don't provide the performance
 necessary for large-scale work and have primitive parallel support.
 These tools are difficult to learn and use and require large time investments.
 We emphasize that before production-scale computations begin, the researchers
 have already developed a mostly functional prototype in an interactive
 computing environment.
 Turning to C/C++/Fortran for production means starting over from scratch
 and maintaining at least two versions of the code moving forward.
 Furthermore, data produced by the compiled version has to be imported back
 into the interactive environment for visualization and analysis.
 The resulting back-and-forth, complex workflow is nearly impossible to
 capture and put into version control systems, again making the computational
 research difficult to reproduce.
\end_layout

\begin_layout Standard
For 
\series bold
publications
\series default
 and
\series bold
 presentations
\series default
, researchers use tools such as LaTeX, Google Docs or Microsoft Word/PowerPoint.
 The most important attribute of these tools in this context is that they
 don't integrate well with version control systems (LaTeX excepted) and
 with other computational tools.
 Digital artifacts (code, data and visualizations) have to be manually pasted
 into these documents, so that the same content is duplicated in many different
 places.
 When the artifacts change, the documents quickly become out of sync.
 
\end_layout

\begin_layout Subsection
A history of two cultures
\end_layout

\begin_layout Subsubsection
The ideals of science and the reality of today's praxis
\end_layout

\begin_layout Standard
Royal society motto, religion vs science, central authority vs the ability
 of individuals to verify, the triumph of reason.
\end_layout

\begin_layout Subsubsection
The early days of computing
\end_layout

\begin_layout Standard
The early days of computing 
\emph on
were open
\emph default
: von Neumann's reports (SIAM article, SIAM review 
\series bold
53
\series default
 (4) 2011, pp607-682.
 A history of how open early computing was.
 
\end_layout

\begin_layout Subsubsection
The software crisis
\end_layout

\begin_layout Standard
Dijkstra's quote, 1972 ACM.
\end_layout

\begin_layout Subsubsection
The world of OSS
\end_layout

\begin_layout Standard
Computing started to close up in the 70's, AT&T's lockdown of Unix and Bill
 Gates' letter to computer hobbyists (Jan'76).
 Stallman's story with printer drivers, a reaction to centralized, locked-down
 models: the GNU/FSF movement is born.
 Linux: OSS for the masses.
 The rise of the internet as powered by linux.
\end_layout

\begin_layout Subsubsection
Why OSS is relevant to science
\end_layout

\begin_layout Itemize
Science becomes computing
\end_layout

\begin_layout Itemize
Both building a hierarchical structure
\end_layout

\begin_layout Itemize
freedom to believe differently
\end_layout

\begin_layout Section
Best practices
\end_layout

\begin_layout Subsection
Distributed version control and collaboration
\end_layout

\begin_layout Subsection
IPython
\end_layout

\begin_layout Standard
We propose that the open source IPython project 
\begin_inset CommandInset citation
LatexCommand cite
key "PER-GRA:2007"

\end_inset

 offers a solution to these problems; a single software tool capable of
 spanning the entire life-cycle of computational research.
 Amongst high-level open source programming languages, Python is today the
 leading tool for general-purpose source scientific computing (along with
 R for statistics), finding wide adoption across research disciplines, education
 and industry and being a core infrastructure tool at institutions such
 as CERN and the Hubble Space Telescope Science Institute 
\begin_inset CommandInset citation
LatexCommand cite
key " Perez2011,ganga09, SST"

\end_inset

.
 The PIs created IPython as a system for interactive and parallel computing
 that is the
\emph on
 de facto
\emph default
 environment for scientific Python.
 In the last year we have developed the IPython Notebook, a web-based
\emph on
 interactive computational notebook
\emph default
 that combines code, text, mathematics, plots and rich media into a single
 document format (see Fig.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:IPython-notebook"

\end_inset

).
 The IPython Notebook was designed to enable researchers to move fluidly
 between all the phases of the research life-cycle and has gained rapid
 adoption.
 It provides an integrated environment for all computation, without locking
 scientists into a specific tool or format: Notebooks can always be exported
 into regular scripts and IPython supports the execution of code in other
 languages such as R, Octave, bash, etc.
 In this project we will expand its capabilities and relevance in the following
 phases of the research cycle: interactive exploration, collaboration and
 publication/presentation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename fig/ipython-notebook-specgram.png
	lyxscale 30
	width 3.2in

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:IPython-notebook"

\end_inset

The web-based IPython Notebook combines explanatory text, mathematics, multimedi
a, code and the results from executing the code.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Changing the culture of science and the role of incentive models
\end_layout

\begin_layout Standard
Science has become computational, but the incentive models of science are
 single-mindedly focused on paper-oriented publications that completely
 ignore the very existence of a computational process.
 Papers are accepted 
\end_layout

\begin_layout Standard
Open*: software, access (Elsevier), education, review.
\end_layout

\begin_layout Section
A contrast in cultures 
\end_layout

\begin_layout Standard
Open source software development uses public fora for most discussion and
 systems for sharing code and data that are, in practice, powerful provenance
 tracking systems.
 There is a strong culture of public disclosure, tracking and fixing of
 bugs, and development often includes exhaustive validation tests that are
 executed automatically whenever changes are made to the software and whose
 output is publicly available on the internet.
 This helps with early detection of problems, mitigates their recurrence,
 and ensures that the state and quality of the software is a known quantity
 under a wide variety of situations (operating systems, inputs, parameter
 ranges, etc).
 Additionally, the same systems that are used for sharing the code track
 the authorship of contributions.
 All of this ensures that open collaboration does not dilute the merit or
 recognition of any individual developer, and allows for a meritocracy of
 contributors to develop while enabling highly effective collaboration.
\end_layout

\begin_layout Standard
In sharp contrast, the incentives in computational research are strongly
 biased towards the rapid publication of papers without any realistic requiremen
t of validation.
 The outcome is that results from publications in computationally-based
 research (applied to any specific field of inquiry) are often, in practice,
 impossible to reproduce.
 Sometimes this is due to the code not being available at all in the first
 place.
 Authors often do make codes available --thus fulfilling a token requirement
 of disclosure-- but in such a state that this disclosure is not a practical
 solution to the reproducibility problem.
 A static archive of source code that has never been tested in a computer
 or operating system outside of the author's, never been audited by external
 eyes and with no automatic testing built into it, is highly unlikely to
 work reliably when used in a completely new environment.
\end_layout

\begin_layout Section
The realities of transplanting approaches 
\end_layout

\begin_layout Standard
Notwithstanding the above, there are real issues with attempting to naïvely
 transplant the practices of open source development verbatim to computational
 research.
 The open source model ends up being one where, in practice, the copyright
 and authorship of any large collaborative project is spread amongst many
 authors, possibly thousands.
 While the source control tools in use do allow for a relatively precise
 provenance analysis to be performed if desired, this is rarely done and
 its success is contingent on the community having followed certain steps
 rigorously to ensure that attribution was correctly recorded during development.
\end_layout

\begin_layout Standard
This is not a major issue in open source, as the rewards mechanisms tend
 to be more informal and based on the overall recognition of any one contributor
 in the community.
 Sometimes people contribute to open source projects as part of their official
 work responsibilities, and in that case a company can enact whatever policies
 it deems necessary; often contributions are made by volunteers for whom
 an acknowledgment in the project's credits is sufficient recognition.
\end_layout

\begin_layout Standard
In contrast, the academic world overwhelmingly weighs the authorship of
 scholarly articles and conference proceedings as the main driver of all
 forms of professional advancement and reward.
 In this system, the pecking order of authorship matters enormously (with
 the many unpleasant consequences familiar to all of us), and so does the
 total number of authors in a publication.
 While in certain communities papers with thousands of authors do exist
 (experimental high-energy physics being the classic example), most scientists
 need the prominent visibility they can achieve in a short author list.
 This dilution of authorship that can result from a largely open collaborative
 development model is an important issue that must be addressed by any proposal
 we present.
\end_layout

\begin_layout Standard
Furthermore, the notion of a fully open development model typical of open
 source projects is at sharp odds with another aspect of the scientific
 publication and reward system: the "first to publish" race.
 Most scientists would, understandably, be very leery of exposing their
 projects to an openly accessible website when in their embryonic stages.
 The fear of being scooped by others is very real, and again we must properly
 address it as we consider how to apply the lessons of open source development
 to the scientific context.
\end_layout

\begin_layout Section
The limits of scientific computational reproducibility 
\end_layout

\begin_layout Standard
As we seek to learn how the open source praxis can inform our scientific
 work, we must recognize that the ideal of scientific reproducibility is
 by necessity a reality of shades.
 We can see a gradation that goes from a pure mathematical result whose
 proof should be accessible to any person skilled in the necessary specialty,
 to one-of-a-kind experiments such as the Large Hadron Collider or the Hubble
 Space Telescope, that can't be reproduced in any realistic sense.
 At each point in this spectrum, however, we can always find ways to improve
 our confidence in the results: whether we re-analyze the same unique datasets
 with independently developed packages run by separate groups or we re-acquire
 partial samplings of critical data multiple times, we should never completely
 renounce the ideals of reproducibility because of practical difficulties.
\end_layout

\begin_layout Standard
Similarly, in computational research we also have certain areas where complete
 reproducibility is more challenging than others.
 Some projects require computations carried on the largest supercomputers
 on the planet, and these are very expensive resources that can't be arbitrarily
 allocated for repeated executions of the same problem.
 Others may require access to enormous datasets that can't easily be transferred
 to the desktop of any researcher wishing to re-execute an analysis.
 But again, alternatives exist: it should be possible to validate scaled
 versions of the largest problems run independently, against scaled specimens
 created on the supercomputers for this very purpose, and sub-sampled datasets
 can be used to collect at least validation statistics that may be informative
 of the trust we place on the published analysis.
\end_layout

\begin_layout Section
Some ideas moving forward 
\end_layout

\begin_layout Standard
Ultimately, while it is true that there are real issues with applying the
 ideals of computational reproducibility from open source software development
 to computational research, we can and must do better.
 We sketch here some ideas on concrete lessons we can learn from software
 development in this direction:
\end_layout

\begin_layout Itemize
Pervasive version control: research codes should be developed, while still
 in-house, 
\emph on
always
\emph default
 using version control systems that track the actual history of everyone's
 contributions.
\end_layout

\begin_layout Itemize
Journals should mandate that upon paper 
\emph on
approval
\emph default
 (but before actual publication and with said publication being conditioned
 on the author meeting this last condition), authors must expose their version
 control system to the public, and that the publicly available version can
 faithfully reproduce (within the limitations discussed above) the published
 results.
 This public version then becomes available for the scientific community
 not only for download, but also as a starting point for further contribution
 and development.
\end_layout

\begin_layout Itemize
By using a distributed version control system, authors can continue to maintain
 a private branch where new work (say leading to a new publication) is conducted
 while tracking the public development.
 This will enable them to maintain exclusive access to their new work until
 it is published, while continuing to develop the openly accessible code
 with the rest of the scientific community.
 Once the code is published, since it was developed using the same version
 control machinery of the public branch, the new contributions can be seamlessly
 merged with the public version and their entire provenance (including informati
on such as time of invention and individual credit within the lab) becomes
 available for inspection.
\end_layout

\begin_layout Standard
In summary, we think that a few simple lessons can be learned from the practices
 of the open source world which, if carefully assimilated, can lead to significa
nt improvements in the state of reproducible computational research.
 
\end_layout

\begin_layout Standard

\lang american
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "ipython"
options "bibtotoc,amsplain"

\end_inset


\end_layout

\end_body
\end_document
